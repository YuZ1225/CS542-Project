# =============================================================================
#
# CS542 Project - Digaai - Logistic Regression Classification
#
# Author: Federico Siano
#
# Date: Oct 27 2018
#
# Only Last Names used as training features
# 
# =============================================================================

import os
import pandas as pd
import numpy as np
import numpy.ma as ma
import hyphen as hp
from hyphen import Hyphenator
import sklearn as sk
from sklearn.linear_model import LogisticRegression as lg
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# Retrieve current working directory (`cwd`)
cwd = os.getcwd()
cwd

# Define directory 
os.chdir("/Users/fsiano/Desktop/Fall2018/CS542/project")

# Assign datsets filename
train = 'digaai_train.csv'
test = 'digaai_test.csv'

# Load spreadsheet
dftrain = pd.read_csv(train, converters = {'first':str, 'last':str})
dftest = pd.read_csv(test, converters = {'Firstname':str, 'Lastname':str})

# Convert test names into lower case for consitency with training set
dftest['Lastname'] = dftest['Lastname'].str.lower()

# Drop name too long
#dftrain = dftrain.drop(32412, axis=0) # handled afterwards with try

# Create Hyphenators
h_pt_PT = Hyphenator('pt_PT')
h_pt_BR = Hyphenator('pt_BR')

# Create Dictionary
last_syll_train = {}
last_syll_test = {}

# Populate dictionary first name
def syllable_dictionary(df, dictionary):
    for word in df:
        try:
            for syll in h_pt_BR.syllables(word):
                if syll not in dictionary:
                    dictionary[syll] = 1
                else:
                    dictionary[syll] += 1
        except:
            print('too long')
                        
syllable_dictionary(dftrain['last'][0:], last_syll_train)
syllable_dictionary(dftest['Lastname'][0:], last_syll_test)

# Create a df with all the features
# Need to create two: (1) train, (2) test
dftrain_slice = pd.DataFrame(np.zeros(shape=(len(dftrain['last'][0:]),len(last_syll_train))), columns=(last_syll_train),index=dftrain['last'][0:])

dftest_slice = pd.DataFrame(np.zeros(shape=(len(dftest['Lastname'][0:]),len(last_syll_train))), columns=(last_syll_train),index=dftest['Lastname'][0:])             

# Populate the dataframe with dummies based on features
def populate_df(df):
    for entry in df.index:
        for syll in df.columns:
            if syll in entry:
                df.loc[entry,syll] = 1
                
populate_df(dftrain_slice)

populate_df(dftest_slice)
            
# Add the y variable
dftrain_slice['y'] = dftrain['b_or_n'][0:].values
#dftest['y'] = dftrain['b_or_n'][:8000].values
            
# Create classifier
classifier = lg()

# Create variables to be used in classification
ncol_train = len(dftrain_slice.columns)
X_train = dftrain_slice[dftrain_slice.columns[0:ncol_train - 1]]
y_train = dftrain_slice[dftrain_slice.columns[ncol_train - 1]]

ncol_test = len(dftest_slice.columns)
X_test = dftest_slice[dftest_slice.columns[0:ncol_test]]
#y_test = dftest[dftest.columns[ncol_test - 1]]

# Train classifier
classifier.fit(X_train, y_train)

# Predict
y_pred = classifier.predict(X_test)

# Accuracy
confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)
print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))
print(classification_report(y_test, y_pred))

# Write .csv file for Kaggle submission
X_test.to_csv('design_matrix_test.csv', sep=',',encoding='utf-8')
np.savetxt('prediction_test.csv', y_pred, delimiter=',')
